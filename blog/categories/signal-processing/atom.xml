<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: signal-processing | LESS IS MORE]]></title>
  <link href="http://r9y9.github.io/blog/categories/signal-processing/atom.xml" rel="self"/>
  <link href="http://r9y9.github.io/"/>
  <updated>2014-06-01T12:35:48+09:00</updated>
  <id>http://r9y9.github.io/</id>
  <author>
    <name><![CDATA[Ryuichi Yamamoto]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[逆連続ウェーブレット変換による信号の再構成]]></title>
    <link href="http://r9y9.github.io/blog/2013/10/21/signal-reconstruction-using-invere-cwt/"/>
    <updated>2013-10-21T01:00:00+09:00</updated>
    <id>http://r9y9.github.io/blog/2013/10/21/signal-reconstruction-using-invere-cwt</id>
    <content type="html"><![CDATA[<p>やったのでメモ。おそらく正しくできたと思う。結果貼っとく。ウェーブレットの参考は以下の文献</p>

<p><a href="http://paos.colorado.edu/research/wavelets/bams_79_01_0061.pdf">Torrence, C. and G.P. Compo &ldquo;A Practical Guide to Wavelet Analysis&rdquo;, Bull. Am. Meteorol. Soc., 79, 61–78, 1998.</a></p>

<h2>ウェーブレットの条件</h2>

<p>マザーウェーブレットはmorletを使う</p>

<p><script type="math/tex; mode=display">
\begin{align}
\psi<em>{0}(\eta) = \pi^{-&frac14;}e^{i\omega</em>{0}\eta}e^{&ndash;\eta^{2}/2}
\end{align}
</script></p>

<p>文献に従って$\omega_{0} = 6.0$とした。</p>

<p>以下にいっぱい図を張る。軸は適当</p>

<h2>元の信号</h2>

<p><img class="center" src="/images/wavelet/original_signal.png" title="&ldquo;The original signal&rdquo;" ></p>

<h2>ウェーブレットスペクトログラム</h2>

<p><img class="center" src="/images/wavelet/morlet_wavelet_spectrogram.png" title="&ldquo;Morlet wavelet spectrogram&rdquo;" ></p>

<p>Gaborではなく、Morletで求めたもの。スケールは、min=55hzで、25cent毎に8オクターブ分取った。一サンプル毎にウェーブレット変換を求めてるので、前回の記事でガボールウェーブレットで求めた奴よりよっぽど解像度高いっすね（前のは10ms毎だった、書いてなかったけど）。見てて綺麗（こなみ</p>

<p>計算はFFT使ってるので速い</p>

<p><a href="http://hp.vector.co.jp/authors/VA046927/gabor_wavelet/gabor_wavelet.html">http://hp.vector.co.jp/authors/VA046927/gabor_wavelet/gabor_wavelet.html</a>
スケールのとり方はここを参考にするといい</p>

<h2>再構成した信号</h2>

<p><img class="center" src="/images/wavelet/recostructed_signal.png" title="&ldquo;The recostructed signal&rdquo;" ></p>

<p>連続ウェーブレットの逆変換は、フーリエ変換と違ってそんなシンプルじゃないんだけど、結果から言えばウェーブレット変換の実数部を足しあわせて適当にスケールすれば元の信号が再構成できるみたい。ほんまかと思って実際にやってみたけど、できた</p>

<p>が、実は少し誤差がある</p>

<h2>重ねてプロット</h2>

<p><img class="center" src="/images/wavelet/double_0.png" title="&ldquo;The original signal and recostructed signal&rdquo;" ></p>

<h2>あっぷ</h2>

<p><img class="center" src="/images/wavelet/double_1.png" title="&ldquo;The original signal and recostructed signal with zoom 1&rdquo;" ></p>

<p><img class="center" src="/images/wavelet/double_2.png" title="&ldquo;The original signal and recostructed signal with zoom 2&rdquo;" ></p>

<p><img class="center" src="/images/wavelet/double_3.png" title="&ldquo;The original signal and recostructed signal with zoom 3&rdquo;" ></p>

<p><img class="center" src="/images/wavelet/double_4.png" title="&ldquo;The original signal and recostructed signal with zoom 4&rdquo;" ></p>

<p><img class="center" src="/images/wavelet/double_5.png" title="&ldquo;The original signal and recostructed signal with zoom 5&rdquo;" ></p>

<p>んー、まぁだいたいあってんじゃないですかね</p>

<h2>誤差</h2>

<p>平均誤差を計算すると、図の縦軸の量で考えて55.3994だった。16bitのwavが-32768〜32767なので、どうだろう、大きいのか小さいのかわからん</p>

<p>ただ、再合成した音声を聞いた所それほど違和感はなかった。これはつまり、スペクトルいじる系の分析にSTFTがではなくウェーブレット使ってもいいんではないか？という考えが生まれますね。果たして、ウェーブレットが音声/音楽の分析にフーリエ変換ほど使われないのはなぜなのか、突き詰めたい</p>

<h2>使った音声</h2>

<p>あなたが一番聞きたいと思った声が流れます、どうぞ</p>

<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/116227502"></iframe>


<p>スペクトログラム表示するのにサンプルが多いと大変なので、48kから10kにサンプリング周波数を落としたもの</p>

<h2>再構成した音声</h2>

<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/116227539"></iframe>


<p>僕の耳では違いはわからない。サンプリング周波数によって誤差が大小する可能性はあるが、そこまで調査してない</p>

<h2>メモ</h2>

<p><a href="http://paos.colorado.edu/research/wavelets/wavelet3.html">http://paos.colorado.edu/research/wavelets/wavelet3.html</a>
ここの最後に書かれている以下の文章、</p>

<blockquote><p>One problem with performing the wavelet transform in Fourier space is that this assumes the time series is periodic. The result is that signals in the wavelet transform at one end of the time series will get wrapped around to the other end.</p></blockquote>

<p>FFT使うウェーブレット変換の問題は、信号を周期関数として仮定してしまうことにある、と。まあ、ですよねー。信号がめちゃくちゃ長くてこの仮定が破綻してしまう場合、どうするのがいいんだろう。</p>

<p>あと、FFT使うウェーブレットの問題として、メモリ食うってのがあるんよな。ウェーブレット変換を計算する前に、マザーウェーブレットのフーリエ変換を持っとかないといけないし、サンプル毎に計算しないといけないし。44.1kの数分の音声とかなると、もう無理っすね。</p>

<p>それぞれ、解決方法は思いつかないでもないけど、まだまとまってないので、解決したらまとめる、かもしれない。</p>

<h2>さらにめも</h2>

<ul>
<li>practicalなんちゃらの、マザーウェーブレットを正規化する部分のmatlabコード、文献中の数式と若干違ってトリッキー。展開すれば一緒なんだけど、文献中の数式をそのまま書いたようになってないので、注意。ちょっと戸惑った</li>
<li>逆ウェーブレットを行う際のスケールにかかる係数（文献中でいう$C_{\delta}$）は、マザーウェーブレットが決まれば値が定まる（らしい）。例えばMorletの$\omega_0 = 6$なら0.776とわかってるので、積分して計算する必要はない</li>
<li>ウェーブレット変換と戯れてたら週末終わった</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[短時間フーリエ変換と連続ウェーブレット変換のvisualization]]></title>
    <link href="http://r9y9.github.io/blog/2013/10/20/wavelet-stft-visualization/"/>
    <updated>2013-10-20T11:46:00+09:00</updated>
    <id>http://r9y9.github.io/blog/2013/10/20/wavelet-stft-visualization</id>
    <content type="html"><![CDATA[<h2>STFT(短時間フーリエ変換)によるスペクトログラム</h2>

<p><img class="center" src="/images/spectrogram_linear_clipped_rev_1.png" title="&ldquo;STFT spectrogram&rdquo;" ></p>

<h2>STFTによるスペクトログラム（Y軸を対数にしたもの）</h2>

<p><img class="center" src="/images/spectrogram_log_clipped_rev_1.png" title="&ldquo;STFT spectrogram (with log-y-axis)&rdquo;" ></p>

<h2>連続ガボールウェーブレット変換によるスペクトログラム</h2>

<p><img class="center" src="/images/wavelet_spectrogram_clipped_rev_1.png" title="&ldquo;Gabor Wavelet spectrogram&rdquo;" ></p>

<p>メモリも軸も無くて発表資料に貼ったら間違いなく怒られる奴だけど許して。でもだいたいの違いはわかると思う。図はgnuplotで作りました</p>

<p>STFTのlog-y-axisと比べるとよくわかるけど、ウェーブレットは低域もちゃんと綺麗にとれてますね。</p>

<p>みんなもっとウェーブレット変換使おう（提案</p>

<h2>分析に使った音声</h2>

<p>決して聞いてはならない</p>

<iframe width="100%" height="166" scrolling="no" frameborder="no" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/116165738"></iframe>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[FFTを使った連続ウェーブレット変換の高速化]]></title>
    <link href="http://r9y9.github.io/blog/2013/10/20/continuous-wavelet-tranform/"/>
    <updated>2013-10-20T00:55:00+09:00</updated>
    <id>http://r9y9.github.io/blog/2013/10/20/continuous-wavelet-tranform</id>
    <content type="html"><![CDATA[<p><img class="center" src="/images/gabor_wavelet_nnmnkwii.png" title="&ldquo;An example of Gabor Wavelet spectrogram (the original wav file is generated using Open Jalk)&rdquo;" ></p>

<h2>そもそもウェーブレット変換って何</h2>

<p><a href="http://ja.wikipedia.org/wiki/%E3%82%A6%E3%82%A7%E3%83%BC%E3%83%96%E3%83%AC%E3%83%83%E3%83%88%E5%A4%89%E6%8F%9B">Jump to wikipedia</a></p>

<p>いわゆる時間周波数解析の手法の一つで、音声、音楽、画像の解析に使われる。直感的には、STFTでいう窓関数の幅を周波数に応じて拡大・伸縮させて、時間変化する信号の特徴を上手く捉えようとする手法のこと</p>

<h2>高速化の仕組み</h2>

<p>さて、本題。ウェーブレット変換は、(スケールパラメータを固定すれば)入力信号とマザーウェーブレットのたたみ込みで表されるので、たたみ込み定理よりフーリエ変換を使った計算方法が存在する。</p>

<p>つまり、</p>

<ul>
<li>入力信号とマザーウェーブレットをそれぞれフーリエ変換する</li>
<li>掛け算する</li>
<li>逆フーリエ変換する</li>
</ul>


<p>というプロセスでウェーブレット変換を求めることができて、かつフーリエ変換にはFFTという高速なアルゴリズムが存在するので、計算を高速化できるという仕組み。まぁ原理としてはシンプルなんだけど以外と面倒くさい（気のせい？）。</p>

<p>色々調べたので、メモ代わりにまとめておく。解説ではなくリンク集です</p>

<h2>A Practical Guide to Wavelet Analysis <a href="http://paos.colorado.edu/research/wavelets/">[web]</a> <a href="http://paos.colorado.edu/research/wavelets/bams_79_01_0061.pdf">[PDF]</a></h2>

<p>結論から言えばここが一番わかりやすかった。</p>

<ul>
<li>実装よりで理論の解説がある</li>
<li>matlab/fortran のコードがある</li>
</ul>


<p>がいいところ</p>

<p>基本的にはこれ読めばわかる。数学全然わからん俺でも読めた。特に、離散表現でのウェーブレットについても書かれているのは良い。連続ウェーブレットといっても、デジタル信号処理で扱う上では離散化しないといけないわけなので</p>

<p>さて、僕が参考にしたmatlabコードへの直リンクは以下</p>

<ul>
<li><a href="http://paos.colorado.edu/research/wavelets/wave_matlab/wave_bases.m">マザーウェーブレットの周波数応答の計算部分</a></li>
<li><a href="http://paos.colorado.edu/research/wavelets/wave_matlab/wavelet.m">連続ウェーブレット変換の本体</a></li>
<li><a href="http://paos.colorado.edu/research/wavelets/wave_matlab/wavetest.m">連続ウェーブレット変換のテストコード</a></li>
</ul>


<p>その他、fortanコードなどいくつかあるので、それらはウェブサイトからどうぞ</p>

<h2>Matlab</h2>

<p> mathworksさんのwavelet toolboxのドキュメントもよかった。ここから上記のpracticalなんちゃらのリンクもある</p>

<ul>
<li><a href="http://www.mathworks.co.jp/jp/help/wavelet/gs/continuous-wavelet-transform.html">Continuous Wavelet Transform</a></li>
<li><a href="http://www.mathworks.co.jp/jp/help/wavelet/ref/cwtft.html">Continuous wavelet transform using FFT algorithm</a></li>
<li><a href="http://www.mathworks.co.jp/jp/help/wavelet/ref/icwtft.html">Inverse CWT</a></li>
</ul>


<p>コードは転がってないですね。まぁ有料なので</p>

<h2>日本語でわかりやすいもの</h2>

<ul>
<li><a href="http://hp.vector.co.jp/authors/VA046927/gabor_wavelet/gabor_wavelet.html">C/C++言語でガボールウェーブレット変換により時間周波数解析を行うサンプルプログラム</a>

<ul>
<li> ここは本当に素晴らしい。何年か前にも参考にさせて頂きました。</li>
</ul>
</li>
<li><a href="http://www.hulinks.co.jp/support/flexpro/v7/dataanalysis_cwt.html">連続ウェーブレット変換 (CWT) &ndash; FlexPro 7 日本語版サポート情報</a>

<ul>
<li> 日本語で丁寧に書かれてる。内容自体は、practicalなんちゃらと似ている</li>
</ul>
</li>
<li><a href="http://www.makino.ecei.tohoku.ac.jp/~aito/wavelet/">東北大学 伊藤先生の講義資料</a>

<ul>
<li> 数少ない日本語でのウェーブレットに関する資料。ただし連続ウェーブレットについてはあんまり解説はない。C言語のサンプル付き</li>
</ul>
</li>
</ul>


<h2>書籍</h2>

<p>今回は調べてない。数年前にちょいちょい調べたことがあるけど忘れた</p>

<h2>その他</h2>

<ul>
<li><a href="https://code.google.com/p/tspl/source/browse/trunk/include/cwt-impl.h?spec=svn2&amp;r=2">tspl Signal Processing Library in C++</a>

<ul>
<li> 連続ウェーブレット変換/逆変換のC++実装。細部までコードは追えてないけど、それっぽいコードがある（俺が読んだ記事とはマザーウェーブレットのnormalizationが違う気もする…</li>
</ul>
</li>
<li><a href="http://dsp.stackexchange.com/questions/10979/inverse-continuous-wavelet-transform-and-matlab">Inverse Continuous Wavelet Transform and matlab &ndash; dsp StackExchange</a>

<ul>
<li> 逆連続ウェーブレット変換教えてーっていう質問。ここでpracticalなんちゃらを知った</li>
</ul>
</li>
<li><a href="http://staff.aist.go.jp/h.fujihara/voice_conversion/">混合音中の歌声の声質変換手法</a>

<ul>
<li> ガチ技術。元産総研の藤原さんが研究開発したもの。<a href="http://staff.aist.go.jp/m.goto/PAPER/SIGMUS201007fujihara.pdf">論文(PDF)</a>の方に少し説明がある。</li>
<li> 声質変換でウェーブレット使うのは僕が知る限りではこれくらい</li>
<li> ちなみに結果めっちゃすごい</li>
</ul>
</li>
</ul>


<h2>さいごに</h2>

<p>以上。ウェーブレット変換は難しいことがわかった（こなみ）。ウェーブレットの利点欠点については書かなかったけれど、音声や音楽を解析したい場合に、時間周波数解析によく用いられる短時間フーリエ解析よりもウェーブレット解析の方が望ましい場合は非常によくあると思っているので、ぜひもっと使われてほしいですね。作ってるライブラリには必ず入れます。</p>

<h2>ちなみに</h2>

<p>計算コストがそこまでボトルネックにならないなら、畳み込みでウェーブレット計算してもいいんじゃないかと思ってる。FFTを使う方法の場合、あるスケールパラメータに対する時間方向のウェーブレット変換係数を一気に求められても、あるシフトパラメータに対する周波数方向のウェーブレット変換係数（つまりある時間でのスペクトルのようなもの）は一気に求められない気がしている。つまり、STFTみたいな形でインクリメンタルにスペクトルは求めにくいんじゃないかってこと（少なくとも自明には思えない）。畳み込み計算するなら、間違いなくできるけど。このあたり理解がまだあやふやなので、間違ってる可能性大</p>

<p>さらにちなみに、僕が作ってたリアルタイムで動く自動伴奏システムは畳み込みでウェーブレット変換してたよ。ウェーブレットよりもアルゴリズムのほうがボトルネックになっていたので全然気にならなかった。参考まで</p>
]]></content>
  </entry>
  
</feed>

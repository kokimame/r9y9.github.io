<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.20.5" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="http://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<link rel="stylesheet" href="/css/normalize.css">
<link rel="stylesheet" href="/css/skeleton.css">
<link rel="stylesheet" href="/css/custom.css">
<link rel="alternate" href="/index.xml" type="application/rss+xml" title="LESS IS MORE">
<link rel="shortcut icon" href="/favicon.png" type="image/x-icon" />
<title>About me - LESS IS MORE</title>
</head>
<body>

<div class="container">

	<header role="banner">
		<div class="header-logo">
			<a href="/"><img src="/images/r9y9.jpg" width="70" height="70"></a>
		</div>
		
	</header>


	<main role="main">
		<article itemscope itemtype="http://schema.org/BlogPosting">
			<h1 class="entry-title" itemprop="headline">About me</h1>
			<span class="entry-meta"><time itemprop="datePublished" datetime="2017-10-03">October 03, 2017</time></span>
			<section itemprop="entry-text">
				

<h2 id="name">Name</h2>

<p>山本 龍一 / Ryuichi Yamamoto</p>

<h2 id="contact-information">Contact information</h2>

<ul>
<li><a href="https://github.com/r9y9">Github</a></li>
<li><a href="https://twitter.com/r9y9">Twitter</a></li>
<li>zryuichi [at] gmail.com</li>
</ul>

<h2 id="interests">Interests</h2>

<ul>
<li>Machine learning and its application to music and audio signals</li>
<li>Statistical voice conversion and text-to-speech synthesis</li>
<li>Music information retrieval</li>
</ul>

<h2 id="work-experience">Work experience</h2>

<ul>
<li>Present: 自由にしています</li>
<li>2013 Apr. ~ 2017 Apr: Computer vision engineer @ チームラボ株式会社</li>
</ul>

<h2 id="education">Education</h2>

<ul>
<li>2013: M.S. in Computer Science @ Nagoya Institute of Technology

<ul>
<li>Thesis title: 多声演奏に頑健な音響信号と楽譜のアライメントと自動伴奏への応用に関する研究（Robust Polyphonic Audio-to-score Alignment and Its Application to Automatic Accompaniment）</li>
</ul></li>
<li>2011: B.S in Computer Science  @ Nagoya Institute of Technology</li>
</ul>

<h2 id="software">Software</h2>

<h3 id="library">Library</h3>

<ul>
<li><a href="https://github.com/r9y9/nnmnkwii">nnmnkwii</a>: Library to build speech synthesis systems designed for easy and fast prototyping.</li>
<li><a href="https://github.com/r9y9/pysptk">pysptk</a>: A python wrapper for Speech Signal Processing Toolkit (SPTK).</li>
<li><a href="https://github.com/r9y9/pylibfreenect2">pylibfreenect2</a>: A python interface for libfreenect2 for python 2.7 and 3.x.</li>
</ul>

<h3 id="code-to-reproduce">Code to reproduce</h3>

<ul>
<li><a href="https://github.com/r9y9/tacotron_pytorch">tacotron_pytorch</a>: PyTorch implementation of Tacotron speech synthesis model.

<ul>
<li><a href="https://arxiv.org/abs/1703.10135">Yuxuan Wang, RJ Skerry-Ryan, Daisy Stanton, et al., &ldquo;Tacotron: Towards End-to-End Speech Synthesis&rdquo;,   arXiv:1703.10135, Apr. 2017.</a></li>
</ul></li>
<li><a href="https://github.com/r9y9/gantts">gantts</a>: PyTorch implementation of GAN-based text-to-speech synthesis and voice conversion (VC).

<ul>
<li><a href="http://ieeexplore.ieee.org/abstract/document/8063435/">Saito, Yuki, Shinnosuke Takamichi, and Hiroshi Saruwatari. &ldquo;Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks.&rdquo; IEEE/ACM Transactions on Audio, Speech, and Language Processing (2017).</a></li>
<li><a href="https://arxiv.org/abs/1707.01670">Shan Yang, Lei Xie, Xiao Chen, Xiaoyan Lou, Xuan Zhu, Dongyan Huang, Haizhou Li, &ldquo;Statistical Parametric Speech Synthesis Using Generative Adversarial Networks Under A Multi-task Learning Framework&rdquo;,     arXiv:1707.01670, Jul 2017.</a></li>
</ul></li>
</ul>

<h2 id="contributions-to-open-source-projects">Contributions to open-source projects</h2>

<ul>
<li><a href="https://github.com/librosa/librosa">librosa</a>: Python library for audio and music analysis.

<ul>
<li>Inverse short-time fourier transform (ISTFT) refinement (<a href="https://github.com/librosa/librosa/pull/235">#235</a>) and bug fixes.</li>
</ul></li>
<li><a href="https://github.com/CSTR-Edinburgh/merlin">merlin</a>: The Neural Network (NN) based Speech Synthesis System.

<ul>
<li>Add python3 support (<a href="https://github.com/CSTR-Edinburgh/merlin/pull/181">#181</a>), CI integration (<a href="https://github.com/CSTR-Edinburgh/merlin/pull/263">#263</a>) and misc bug fixes.</li>
</ul></li>
<li><a href="http://sp-tk.sourceforge.net/">SPTK</a>: Speech Signal Processing Toolkit (SPTK)

<ul>
<li>Bug report and bug fixes.</li>
</ul></li>
<li><a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder">Python-Wrapper-for-World-Vocoder</a>: A Python wrapper for the high-quality vocoder &ldquo;World&rdquo;

<ul>
<li>Add support for spectral envelope encode/decode functions (<a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder/pull/8">#8</a>) and misc improvements.</li>
</ul></li>
<li><a href="https://github.com/k2kobayashi/sprocket">sprocket</a>: A voice conversion toolkit intended to be used as baseline for <a href="http://www.vc-challenge.org/">voice conversion challenge 2016</a>.

<ul>
<li>Design discussion, integrate WORLD vocoder and bug fixes.</li>
</ul></li>
</ul>

<h2 id="competitions">Competitions</h2>

<ul>
<li><a href="https://deepanalytics.jp/compe/36">第1回 FR FRONTIER ：ファッション画像における洋服の「色」分類</a> 8 / 218 位.</li>
<li><a href="https://deepanalytics.jp/compe/32">【(1)料理領域検出部門】人工知能技術戦略会議主催 第1回AIチャレンジコンテスト
</a>: 10 / 37 位.</li>
</ul>

<h2 id="research-projects">Research projects</h2>

<ul>
<li>2012 - 2013: MIDI入力自動伴奏システムの研究、開発 <a href="http://hil.t.u-tokyo.ac.jp/software/Eurydice/">[デモ動画]</a></li>
<li>2013 - 2014: Ryry: 音響入力自動伴奏システムの研究、開発 <a href="https://www.youtube.com/watch?v=qQHNUk6ufK8">[デモ動画]</a></li>
</ul>

<h2 id="awards">Awards</h2>

<ul>
<li>2013: 日本音響学会学生優秀発表賞 @ 第7回（2013年春季研究発表会）<a href="http://www.asj.gr.jp/recommending/07_gakusei.html">参考URL</a></li>
<li>2012: 日本音響学会東海支部優秀発表賞 <a href="http://www.asj-tokai.jp/activities/awardees">参考URL</a></li>
</ul>

<h2 id="publications">Publications</h2>

<p><a href="https://scholar.google.co.jp/citations?user=PpjbClsAAAAJ&amp;hl=ja">https://scholar.google.co.jp/citations?user=PpjbClsAAAAJ&amp;hl=ja</a></p>

				
<div class="social">
    <div>
        <a href="https://twitter.com/share" class="twitter-share-button" data-via="r9y9" data-text="About me" data-related="r9y9">Tweet</a>
        <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
    </div>
</div>


			</section>
		</article>
	</main>


	<footer role="contentinfo">
		<div class="hr"></div>
		<address>
			<div class="avatar-bottom">
				<a href="/">
					
					<img src="/images/r9y9.jpg">
					
				</a>
			</div>

		<div class="copyright">Copyright &copy;
			<a href="/about">Ryuichi YAMAMOTO</a> All rights reserved.

			<a href="https://github.com/r9y9">
				<span class="github">r9y9@Github</span>
			</a>
		</div>
		</address>
	</footer>

</div>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-44433856-1', 'auto');
	ga('send', 'pageview');
</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         HTML: ["input/TeX","output/HTML-CSS"],
         TeX: {
                Macros: {
                         bm: ["\\boldsymbol{#1}", 1],
                         argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                         argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
                extensions: ["AMSmath.js","AMSsymbols.js"],
                equationNumbers: { autoNumber: "AMS" } },
         extensions: ["tex2jax.js"],
         jax: ["input/TeX","output/HTML-CSS"],
         tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true },
         "HTML-CSS": { availableFonts: ["TeX"],
                       linebreaks: { automatic: true } }
     });
 </script>

 <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       }
     });
 </script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>




</body>
</html>


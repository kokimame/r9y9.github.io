<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: speech-signal-processing | LESS IS MORE]]></title>
  <link href="http://r9y9.github.io/blog/categories/speech-signal-processing/atom.xml" rel="self"/>
  <link href="http://r9y9.github.io/"/>
  <updated>2014-06-13T02:37:37+09:00</updated>
  <id>http://r9y9.github.io/</id>
  <author>
    <name><![CDATA[Ryuichi Yamamoto]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[GOSSP - Go言語で音声信号処理]]></title>
    <link href="http://r9y9.github.io/blog/2014/06/08/gossp-speech-signal-processing-for-go/"/>
    <updated>2014-06-08T00:56:00+09:00</updated>
    <id>http://r9y9.github.io/blog/2014/06/08/gossp-speech-signal-processing-for-go</id>
    <content type="html"><![CDATA[<h1>C++からGoへ</h1>

<p>みなさん、C++で信号処理のアルゴリズムを書くのはつらいと思ったことはありませんか？C++で書くと速いのはいいけれど、いかんせん書くのが大変、コンパイルエラーは読みづらい、はたまたライブラリをビルドしようとしたら依存関係が上手く解決できず……そんな覚えはないでしょうか？謎のコンパイルエラーに悩みたくない、ガーベジコレクションほしい、Pythonのようにさくっと書きたい、型推論もほしい、でも動作は速い方がいい、そう思ったことはないでしょうか。</p>

<p>そこでGoです。もちろん、そういった思いに完全に答えてくれるわけではありませんが、厳しいパフォーマンスを要求される場合でなければ、Goの方が良い場合も多いと僕は思っています。
とはいえ、まだ比較的新しい言語のため、ライブラリは少なく信号処理を始めるのも大変です。というわけで、僕がC++をやめてGoに移行したことを思い出し、Goでの信号処理の基礎と、今まで整備してきたGoでの音声信号処理ライブラリを紹介します。</p>

<p>Goの良いところ/悪いところについては書きません。正直、本当は何の言語でもいいと思っていますが、僕はGoが好きなので、ちょっとでもGoで信号処理したいと思う人が増えるといいなーと思って書いてみます。</p>

<p>あとで書きますが、僕が書いたコードで使えそうなものは、以下にまとめました。</p>

<p><a href="https://github.com/r9y9/gossp">https://github.com/r9y9/gossp</a></p>

<h1>基礎</h1>

<h2>Wavファイルの読み込み/書き込み <a href="http://godoc.org/github.com/mjibson/go-dsp/wav">[wav]</a></h2>

<p><img class="center" src="/images/speech_signal.png" title="&ldquo;Speech signal example.&rdquo;" ></p>

<p>まずは音声ファイルの読み込みですね。wavファイルの読み込みさえできれば十分でしょう。</p>

<p>これは、すでに有用なライブラリが存在します。<a href="https://github.com/mjibson/go-dsp">GO-DSP</a> とういデジタル信号処理のライブラリに含まれるwavパッケージを使いましょう。</p>

<p>次のように書くことができます。</p>

<p>```go
package main</p>

<p>import (</p>

<pre><code>"fmt"
"github.com/mjibson/go-dsp/wav"
"log"
"os"
</code></pre>

<p>)</p>

<p>func main() {</p>

<pre><code>// ファイルのオープン
file, err := os.Open("./test.wav")
if err != nil {
    log.Fatal(err)
}

// Wavファイルの読み込み 
w, werr := wav.ReadWav(file)
if werr != nil {
    log.Fatal(werr)
}

// データを表示
for i, val := range w.Data {
    fmt.Println(i, val)
}
</code></pre>

<p>}
```</p>

<p>簡単ですね。</p>

<p>Goはウェブ周りの標準パッケージが充実しているので、以前<a href="http://qiita.com/r9y9/items/35a1cf139332a3072fc8">qiitaに書いた記事</a>のように、wavファイルを受け取って何らかの処理をする、みたいなサーバも簡単に書くことができます</p>

<p>wavファイルの書き込み＋ユーティリティを追加したかったので、僕は自分でカスタムしたパッケージを使っています。</p>

<p><a href="https://github.com/r9y9/go-dsp">https://github.com/r9y9/go-dsp</a></p>

<h2>高速フーリエ変換 (Fast Fourier Transform; FFT) <a href="http://godoc.org/github.com/mjibson/go-dsp/fft">[fft]</a></h2>

<p>言わずとしれたFFTです。音のスペクトルを求めるのに必須の処理です。で、Goではどうすればいいのか？ということですが、こちらもすでに有用なライブラリが存在します。<a href="https://github.com/mjibson/go-dsp">GO-DSP</a>に含まれる、fftパッケージを使いましょう。</p>

<p>このfftパッケージは、go routinesを使って平行化されているため速いです。僕は、1次元のフーリエ変換以外めったに使いませんが、N次元のフーリエ変換をサポートしているのもこのライブラリのいいところです。</p>

<h3>参考</h3>

<ul>
<li><a href="http://mattjibson.com/blog/2013/01/04/go-dsp-fft-performance-with-go-routines/">go-dsp FFT performance with go routines · Matt Jibson</a></li>
</ul>


<p>使い方は、とても簡単です。</p>

<p>```go
package main</p>

<p>import (</p>

<pre><code>"fmt"
"github.com/mjibson/go-dsp/fft"
</code></pre>

<p>)</p>

<p>func main() {</p>

<pre><code>fmt.Println(fft.FFTReal([]float64{1, 2, 3, 4, 5, 6, 7, 8}))
</code></pre>

<p>}
```</p>

<h2>離散コサイン変換 (Discrete Cosine Transform; DCT) <a href="http://godoc.org/github.com/r9y9/gossp/dct">[dct]</a></h2>

<p>DCTは、Mel-Frequency Cepstrum Coefficients (通称MFCC) 求めるのに必要な変換です。こちらは、残念ながら良さそうなライブラリがなかったので、自分で書きました。</p>

<p>使い方はFFTとほとんど一緒です。</p>

<p>```go
package main</p>

<p>import (</p>

<pre><code>"fmt"
"github.com/r9y9/gossp/dct"
</code></pre>

<p>)</p>

<p>func main() {</p>

<pre><code>y := dct.DCTOrthogonal([]float64{1, 2, 3, 4, 5, 6, 7, 8})
fmt.Println(dct.IDCTOrthogonal(y)) // 直交変換では、逆変換すると元に戻る
</code></pre>

<p>}
```</p>

<p>さて、基本的なところは一旦ここまでです。次からは、少し音声寄りの信号処理手法の紹介です。</p>

<h1>時間周波数解析</h1>

<h2>短時間フーリエ変換 (Short Time Fourier Transform; STFT) <a href="http://godoc.org/github.com/r9y9/gossp/stft">[stft]</a></h2>

<p><img class="center" src="/images/stft.png" title="&ldquo;STFT spectrogram&rdquo;" ></p>

<p>STFTは、音声の時間周波数解析手法として定番の方法ですね。音声を可視化したり、何らかの認識アルゴリズムの特徴抽出に使ったり、まぁ色々です。</p>

<p>次のようなコードを書くと、スペクトログラムが作れます</p>

<p>```go
package main</p>

<p>import (</p>

<pre><code>"flag"
"fmt"
"github.com/r9y9/gossp"
"github.com/r9y9/gossp/io"
"github.com/r9y9/gossp/stft"
"github.com/r9y9/gossp/window"
"log"
"math"
</code></pre>

<p>)</p>

<p>func main() {</p>

<pre><code>filename := flag.String("i", "input.wav", "Input filename")
flag.Parse()

w, werr := io.ReadWav(*filename)
if werr != nil {
    log.Fatal(werr)
}
data := w.GetMonoData()

s := &amp;stft.STFT{
    FrameShift: int(float64(w.SampleRate) / 100.0), // 0.01 sec,
    FrameLen:   2048,
    Window:     window.CreateHanning(2048),
}

spectrogram, _ := gossp.SplitSpectrogram(s.STFT(data))
PrintMatrixAsGnuplotFormat(spectrogram)
</code></pre>

<p>}</p>

<p>func PrintMatrixAsGnuplotFormat(matrix [][]float64) {</p>

<pre><code>fmt.Println("#", len(matrix[0]), len(matrix))
for i, vec := range matrix {
    for j, val := range vec {
        fmt.Println(i, j, math.Log(val))
    }
    fmt.Println("")
}
</code></pre>

<p>}
```</p>

<p>上の画像は、gnuplotで表示したものです</p>

<p><code>
set pm3d map
sp "spepctrogram.txt"
</code></p>

<h2>逆短時間フーリエ変換 (Inverse Short Time Fourier Transform; ISTFT) <a href="http://godoc.org/github.com/r9y9/gossp/stft">[stft]</a></h2>

<p>ISTFTは、STFTの逆変換でスペクトログラムから時間領域の信号に戻すために使います。スペクトログラムを加工するような音源分離、ノイズ除去手法を使う場合には、必須の処理です。これはstftと同じパッケージ下にあります。</p>

<p>```</p>

<pre><code>reconstructed := s.ISTFT(spectrogram)
</code></pre>

<p>```</p>

<p>これで、スペクトログラムから音声を再構築することができます。</p>

<p>逆変換の仕組みは、意外と難しかったりします。</p>

<ul>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.306.7858">D. W. Griffin and J. S. Lim, &ldquo;Signal estimation from modified short-time Fourier transform,&rdquo; IEEE Trans. ASSP, vol.32, no.2, pp.236–243, Apr. 1984.</a></li>
<li><a href="http://research.cs.tamu.edu/prism/lectures/sp/l6.pdf">L6: Short-time Fourier analysis and synthesis</a></li>
<li><a href="http://yukara-13.hatenablog.com/entry/2013/11/17/210204">Pythonで短時間フーリエ変換（STFT）と逆変換 &ndash; 音楽プログラミングの超入門（仮）</a></li>
</ul>


<p>この辺を参考にしました。興味のある人は読んで見てください。</p>

<h2>連続ウェーブレット変換 (Continuous Wavelet Transform; CWT)</h2>

<p><img class="center" src="/images/morlet_6_log.png" title="&ldquo;Morlet Wavelet spectrogram&rdquo;" ></p>

<p>これは何回かブログで書きました。</p>

<ul>
<li><a href="http://r9y9.github.io/blog/2013/10/20/continuous-wavelet-tranform/">FFTを使った連続ウェーブレット変換の高速化 &ndash; LESS IS MORE</a></li>
<li><a href="http://r9y9.github.io/blog/2014/06/01/continuouos-wavelet-transform-types/">連続ウェーブレット変換に使うマザーウェーブレット色々: Morlet, Paul, DOG &ndash; LESS IS MORE</a></li>
</ul>


<p>コードは、テストがまだ通らないので開発中ということで…orz</p>

<h2>逆連続ウェーブレット変換 (Inverse Continuous Wavelet Transform; ICWT)</h2>

<p>連続ウェーブレット変換の逆変換ですね。これもけっこう難しいです。こちらもまだテストに通っていないので、開発中です。</p>

<ul>
<li><a href="http://r9y9.github.io/blog/2013/10/21/signal-reconstruction-using-invere-cwt/">逆連続ウェーブレット変換による信号の再構成 &ndash; LESS IS MORE</a></li>
</ul>


<p>さて、この辺でまた一区切りです。次は、より音声に特化した信号処理手法を紹介します。</p>

<p>※以降紹介するもののうち、多くは<a href="http://sp-tk.sourceforge.net/">SPTK</a>のGo-portになっていて、一部はcgoを使ってラップしただけです（後々はpure goにしたいけれど、特にメルケプストラム分析あたりは難しいのでできていません）</p>

<h1>音声分析系</h1>

<h2>基本周波数推定 <a href="http://godoc.org/github.com/r9y9/gossp/f0">[f0]</a></h2>

<p><img class="center" src="/images/arayuru_f0.png" title="&ldquo;Fundamental frequency trajectory example.&rdquo;" ></p>

<p>ざっくり言えば音の高さを求める方法ですね。一応、音声に特化した方法をいくつか使えるようにしました。</p>

<ul>
<li><a href="http://audition.ens.fr/adc/pdf/2002_JASA_YIN.pdf">A. de Cheveigne and H. Kawahara. YIN, a fundamental frequency estimator for speech and music. J. Acoust. Soc. Am., 111(4):1917–1930, 2002.</a></li>
<li><a href="http://www.cise.ufl.edu/~acamacho/publications/dissertation.pdf">A. Camacho. SWIPE: A sawtooth waveform inspired pitch estimator for speech and music. PhD thesis, University of Florida, 2007.</a></li>
</ul>


<p>ただしYINはもどきです。</p>

<p>以前、<a href="https://github.com/r9y9/go-world">GO-WORLD</a>という音声分析合成系WORLDのGoラッパーを書いたので、それを使えばF0推定手法Dioが使えます。</p>

<h3>参考</h3>

<ul>
<li><a href="http://r9y9.github.io/blog/2014/03/22/go-world/">音声分析変換合成システムWORLDのGoラッパーを書いた &ndash; LESS IS MORE</a></li>
</ul>


<h2>メルケプストラム分析 <a href="http://godoc.org/github.com/r9y9/gossp/mgcep">[mgcep]</a></h2>

<p>音声合成界隈ではよく聞くメルケプストラム（※MFCCとは異なります）を求めるための分析手法です。メルケプストラムは、HMM（Hidden Markov Models; 隠れマルコフモデル）音声合成や統計的声質変換において、声道特徴（いわゆる、声質）のパラメータ表現としてよく使われています。メルケプストラムの前に、LPCとかPARCORとか色々あるのですが、現在のHMM音声合成で最もよく使われているのはメルケプストラムな気がするので、メルケプストラム分析があれば十分な気がします。</p>

<p>これは、SPTKをcgoを使ってラップしました</p>

<h3>参考</h3>

<ul>
<li><a href="http://ci.nii.ac.jp/naid/40004638236/">徳田恵一, 小林隆夫, 深田俊明, 斎藤博徳, 今井 聖, “メルケプストラムをパラメータとする音声のスペクトル推定,” 信学論(A), vol.J74-A, no.8, pp.1240–1248, Aug. 1991.</a></li>
</ul>


<h2>メル一般化ケプストラム分析 <a href="http://godoc.org/github.com/r9y9/gossp/mgcep">[mgcep]</a></h2>

<p>メル一般化ケプストラム分析は、その名の通りメルケプストラム分析を一般化したものです。メルケプストラム分析はもちろん、LPCも包含します（詳細は、参考文献をチェックしてみてください）。論文をいくつかあさっている限り、あんまり使われていない気はしますが、これもSPTKをラップしてGoから使えるようにしました。メルケプストラム分析もメル一般化ケプストラム分析に含まれるので、mgcepという一つのパッケージにしました。</p>

<h3>参考</h3>

<ul>
<li><a href="http://www.utdallas.edu/~john.hanse/nPublications/JP-55-SpeechComm-Yapanel-Hansen-PMVDR-Feb08.pdf">Tokuda, K., Masuko, T., Kobayashi, T., Imai, S., 1994. Mel-generalized Cepstral Analysis-A Uniﬁed Approach to Speech Spectral Estimation, ISCA ICSLP-94: Inter. Conf. Spoken Lang. Proc., Yokohama, Japan, pp. 1043–1046.</a></li>
</ul>


<h1>音声合成系</h1>

<h2>励起信号の生成 <a href="http://godoc.org/github.com/r9y9/gossp/excite">[excite]</a></h2>

<p><img class="center" src="/images/pulse_excite.png" title="&ldquo;Exciation eignal.&rdquo;" ></p>

<p>SPTKのexciteのGo実装です。いわゆるPulseExcitationという奴ですね。非周期成分まったく考慮しない単純な励起信号です。</p>

<p>高品質な波形合成が必要な場合は、WORLDやSTRAIGHTを使うのが良いです。</p>

<h2>MLSA (Mel Log Spectrum Approximation) デジタルフィルタ <a href="http://godoc.org/github.com/r9y9/gossp/vocoder">[vocoder]</a></h2>

<p>MLSAフィルタは、メルケプストラムと励起信号から音声波形を合成するためのデジタルフィルタです。HMM音声合成の波形合成部で使われています（今もきっと）。Pure goで書き直しました。</p>

<p>昔、C++でも書いたことあります。</p>

<h3>参考</h3>

<ul>
<li><a href="http://r9y9.github.io/blog/2013/12/01/mlsa-filter-with-c-plus-plus/">MLSA digital filter のC++実装 &ndash; LESS IS MORE</a></li>
</ul>


<h2>MGLSA (Mel Genaralized-Log Spectrum Approximation) デジタルフィルタ <a href="http://godoc.org/github.com/r9y9/gossp/vocoder">[vocoder]</a></h2>

<p>MGLSAフィルタは、メル一般化ケプストラムから波形を合成するためのデジタルフィルタですね。これも pure goで書きました。</p>

<h2><strong>※SPTKの再実装について</strong></h2>

<p>SPTKの実装をGoで書き直したものについては、SPTKの実装と結果が一致するかどうかを確認するテストを書いてあります。よって、誤った結果になるということは（計算誤差が影響する場合を除き）基本的にないので、お気になさらず。</p>

<h2>高品質な音声分析変換合成系 WORLD <a href="http://godoc.org/github.com/r9y9/go-world">[go-world]</a></h2>

<p><a href="http://r9y9.github.io/blog/2014/03/22/go-world/">音声分析変換合成システムWORLDのGoラッパーを書いた &ndash; LESS IS MORE</a></p>

<p>以前WORLDのGoラッパーを書いたので、色々使えると思います。統計ベースの音声合成とか、声質変換とか。僕は声質変換に使おうと思ってラップしました。</p>

<h1>おわりに</h1>

<p>長々と書きましたが、Go言語での信号処理の基礎と、今まで整備してきた音声信号処理ライブラリを簡単に紹介しました。僕が書いたものは、まとめてGithubで公開しています。</p>

<p><a href="https://github.com/r9y9/gossp">https://github.com/r9y9/gossp</a></p>

<p>使ってももらって、あわよくばバグとか報告してもらって、改善していければいいなーというのと、あとGithubのissue管理便利だし使おうと思ってGithubに上げました。</p>

<p>みなさん、Goで音声信号処理始めてみませんか？</p>

<h1>余談</h1>

<h2>Pythonではダメなの？その他言語は？</h2>

<p>なんでGoなの？と思う人がいると思います。冒頭にも書いたとおり、正直好きなのにすればいいですが、適当に書いて速いのがいいならC++だし、型を意識せずさくっと書きたいならPythonだし、そこそこ速くて型があって型推論もあって、とかだったらGoがいいかなと僕は思います。</p>

<p>Goの特徴（≒良さ）ついては、<a href="http://www.slideshare.net/ymotongpoo/20130228-gobp-study-66-16830134">20130228 Goノススメ（BPStudy #66） | SlideShare</a>
 の11枚目が僕にはドンピシャです。</p>

<p>numpy, scipy, matplotlib, scikit-learnあたりが最強すぎるので、僕はpythonも良く使います。</p>

<h2>きっかけ</h2>

<p>この記事を書いたきっかけは、友人にGoをおすすめしまくっていたのに全然聞いてくれなかったからでした。Goでも信号処理はできるよ</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MLSA digital filter のC++実装]]></title>
    <link href="http://r9y9.github.io/blog/2013/12/01/mlsa-filter-with-c-plus-plus/"/>
    <updated>2013-12-01T23:43:00+09:00</updated>
    <id>http://r9y9.github.io/blog/2013/12/01/mlsa-filter-with-c-plus-plus</id>
    <content type="html"><![CDATA[<p><a href="http://r9y9.github.io/blog/2013/09/23/mlsa-filter-wakaran/">MLSAフィルタわからん</a>という記事を書いて早2ヶ月、ようやく出来た。</p>

<p>Mel-log spectrum approximate (MLSA) filterというのは、対数振幅スペクトルを近似するようにメルケプストラムから直接音声を合成するデジタルフィルタです。<a href="http://sp-tk.sourceforge.net/">SPTK</a>のmlsa filterと比較して完全に計算結果が一致したので、間違ってはないはず。MLSAフィルタを使ってメルケプから音声合成するプログラムをC++で自分で書きたいという稀有な人であれば、役に立つと思います。基本的に、SPTKのmlsa filterの再実装です。</p>

<h1>mlsa_filter.h</h1>

<p><a href="https://gist.github.com/r9y9/7735120">https://gist.github.com/r9y9/7735120</a></p>

<p>```cpp</p>

<h1>pragma once</h1>

<h1>include <cmath></h1>

<h1>include <memory></h1>

<h1>include <vector></h1>

<h1>include <cassert></h1>

<p>namespace sp {</p>

<p>/<em>*
 * MLSA BASE digital filter (Mel-log Spectrum Approximate digital filter)
 </em>/
class mlsa_base_filter {
public:
  mlsa_base_filter(const int order, const double alpha);</p>

<p>  template <class Vector>
  double filter(const double x, const Vector&amp; b);</p>

<p> private:
  mlsa_base_filter();</p>

<p>  double alpha<em>;
  std::vector<double> delay</em>;
};</p>

<p>mlsa_base_filter::mlsa_base_filter(const int order, const double alpha)
: alpha<em>(alpha),
  delay</em>(order+1)
{
}</p>

<p>template <class Vector>
double mlsa_base_filter::filter(const double x, const Vector&amp; b)
{
  double result = 0.0;</p>

<p>  delay<em>[0] = x;
  delay</em>[1] = (1.0-alpha<em>*alpha</em>)<em>delay<em>[0] + alpha</em></em>delay_[1];</p>

<p>  for (size_t i = 2; i &lt; b.size(); ++i) {</p>

<pre><code>delay_[i] = delay_[i] + alpha_*(delay_[i+1]-delay_[i-1]);
result += delay_[i] * b[i];
</code></pre>

<p>  }</p>

<p>  // special case
  // TODO: other solution?
  if (b.size() == 2) {</p>

<pre><code>result += delay_[1] * b[1];
</code></pre>

<p>  }</p>

<p>  // t &lt;&ndash; t+1 in time
  for (size_t i = delay_.size()-1; i > 1; &mdash;i) {</p>

<pre><code>delay_[i] = delay_[i-1];
</code></pre>

<p>  }</p>

<p>  return result;
}</p>

<p>/<em>*
 * MLSA digital filter cascaded
 </em>/
class mlsa_base_cascaded_filter {
 public:
  mlsa_base_cascaded_filter(const int order,</p>

<pre><code>            const double alpha,
            const int n_pade);
</code></pre>

<p>  template <class Vector>
  double filter(const double x, const Vector&amp; b);</p>

<p> private:
  mlsa_base_cascaded_filter();</p>

<p>  std::vector&lt;std::unique_ptr&lt;mlsa_base_filter>> base_f<em>; // cascadad filters
  std::vector<double> delay</em>;
  std::vector<double> pade_coef_;
};</p>

<p>mlsa_base_cascaded_filter::mlsa_base_cascaded_filter(const int order,</p>

<pre><code>                         const double alpha,
                         const int n_pade)
</code></pre>

<p>  : delay<em>(n_pade + 1),
  pade_coef</em>(n_pade + 1)
{
  using std::unique_ptr;</p>

<p>  if (n_pade != 4 &amp;&amp; n_pade != 5) {</p>

<pre><code>std::cerr &lt;&lt; "The number of pade approximations must be 4 or 5."
      &lt;&lt; std::endl;
</code></pre>

<p>  }
  assert(n_pade == 4 || n_pade == 5);</p>

<p>  for (int i = 0; i &lt;= n_pade; ++i) {</p>

<pre><code>mlsa_base_filter* p = new mlsa_base_filter(order, alpha);
base_f_.push_back(unique_ptr&lt;mlsa_base_filter&gt;(p));
</code></pre>

<p>  }</p>

<p>  if (n_pade == 4) {</p>

<pre><code>pade_coef_[0] = 1.0;
pade_coef_[1] = 4.999273e-1;
pade_coef_[2] = 1.067005e-1;
pade_coef_[3] = 1.170221e-2;
pade_coef_[4] = 5.656279e-4;
</code></pre>

<p>  }</p>

<p>  if (n_pade == 5) {</p>

<pre><code>pade_coef_[0] = 1.0;
pade_coef_[1] = 4.999391e-1;
pade_coef_[2] = 1.107098e-1;
pade_coef_[3] = 1.369984e-2;
pade_coef_[4] = 9.564853e-4;
pade_coef_[5] = 3.041721e-5;
</code></pre>

<p>  } <br/>
}</p>

<p>template <class Vector>
double mlsa_base_cascaded_filter::filter(const double x, const Vector&amp; b)
{
  double result = 0.0;<br/>
  double feed_back = 0.0;</p>

<p>  for (size_t i = pade_coef_.size()-1; i >= 1; &mdash;i) {</p>

<pre><code>delay_[i] = base_f_[i]-&gt;filter(delay_[i-1], b);
double v = delay_[i] * pade_coef_[i];
if (i % 2 == 1) {
  feed_back += v;
} else {
  feed_back -= v;
}
result += v;
</code></pre>

<p>  }</p>

<p>  delay<em>[0] = feed_back + x;
  result += delay</em>[0];</p>

<p>  return result;
}</p>

<p>/<em>*
 * MLSA digital filter (Mel-log Spectrum Approximate digital filter)
 * The filter consists of two stage cascade filters
 </em>/
class mlsa_filter {
 public:
  mlsa_filter(const int order, const double alpha, const int n_pade);
 ~mlsa_filter();</p>

<p> template <class Vector>
 double filter(const double x, const Vector&amp; b);</p>

<p> private:
 mlsa_filter();</p>

<p>  double alpha<em>;
  std::unique_ptr&lt;mlsa_base_cascaded_filter> f1</em>; // first stage
  std::unique_ptr&lt;mlsa_base_cascaded_filter> f2_; // second stage
};</p>

<p>mlsa_filter::mlsa_filter(const int order,</p>

<pre><code>         const double alpha,
         const int n_pade)
</code></pre>

<p>  : alpha<em>(alpha),
  f1</em>(new mlsa_base_cascaded_filter(2, alpha, n_pade)),
  f2_(new mlsa_base_cascaded_filter(order, alpha, n_pade))
{
}</p>

<p>mlsa_filter::~mlsa_filter()
{
}</p>

<p>template <class Vector>
double mlsa_filter::filter(const double x, const Vector&amp; b)
{
  // 1. First stage filtering
  Vector b1 = {0, b[1]};
  double y = f1_&ndash;>filter(x, b1);</p>

<p>  // 2. Second stage filtering
  double result = f2_&ndash;>filter(y, b);</p>

<p>  return result;
}</p>

<p>} // end namespace sp
```</p>

<h1>使い方</h1>

<p>mlsa_filter.hをインクルードすればおｋ</p>

<p>```</p>

<h1>include &ldquo;mlsa_filter.h&rdquo;</h1>

<p>// セットアップ
const double alpha = 0.42;
const int order = 30;
const int n_pade = 5;
sp::mlsa_filter mlsa_f(order, alpha, n_pade);</p>

<p>&hellip;
// MLSA フィルタリング
出力一サンプル = mlsa_f.filter(入力一サンプル, フィルタ係数);
```</p>

<h1>何で再実装したのか</h1>

<ul>
<li>mlsa filterをC++的なインタフェースで使いたかった</li>
<li>コード見たらまったく意味がわからなくて、意地でも理解してやろうと思った</li>
<li>反省はしている</li>
<li>知り合いの声質変換やってる方がMLSAフィルタを波形合成に使ってるっていうし、ちょっとやってみようかなって</li>
<li>あと最近音声合成の低レベルに手をつけようとと思ってたし勉強にもなるかなって</li>
<li>思ったんだ……んだ…だ…</li>
</ul>


<p>車輪の再開発はあんま良くないと思ってるけど許して。
誰かがリファクタせないかんのだ</p>

<h1>感想</h1>

<p>SPTKのmlsa filterは、正直に言うとこれまで読んできたコードの中で一二を争うほど難解でした（いうてC言語はあまり読んできてないので、Cだとこれが普通なのかもしれないけど）。特に、元コードの d: delayという変数の使われ方が複雑過ぎて、とても読みにくくございました。MLSAフィルタは複数のbase filterのcascade接続で表されるわけだけど、それぞれの遅延が一つのdという変数で管理されていたのです。つまり、</p>

<ul>
<li>d[1] ~ d[5] までは、あるフィルタの遅延</li>
<li>d[6] ~ d[11] までは、別のフィルタの遅延</li>
<li>d[12] ~ にはまた別のフィルタの遅延</li>
</ul>


<p>という感じです。</p>

<p>改善しようと思って、base filterというクラスを作ってそのクラスの状態として各フィルタの遅延を持たせて、見通しを良くしました</p>

<h2>さいごに</h2>

<p>MLSAフィルタ、難しいですね（小並感</p>

<p>いつかリアルタイム声質変換がやってみたいので、それに使う予定（worldを使うことになるかもしれんけど）。戸田先生当たりがやってる声質変換を一回真似してみたいと思ってる</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SPTKをC++から使えるようにする]]></title>
    <link href="http://r9y9.github.io/blog/2013/12/01/sptk-with-waf/"/>
    <updated>2013-12-01T18:46:00+09:00</updated>
    <id>http://r9y9.github.io/blog/2013/12/01/sptk-with-waf</id>
    <content type="html"><![CDATA[<p><a href="http://sp-tk.sourceforge.net/">音声信号処理ツールキットSPTK</a>をC++から使おうと思ったら意外とハマってしまったので、</p>

<ul>
<li>C++から使えるようにC++コンパイラでコンパイルできるようにした</li>
<li>使いやすいようにwafを組み込みんだ</li>
</ul>


<p>リポジトリ: <a href="https://github.com/r9y9/SPTK">https://github.com/r9y9/SPTK</a></p>

<p>というわけで、使い方について簡単に書いておく</p>

<h1>SPTK について</h1>

<ul>
<li>SPTKを使うと何ができるか: <a href="http://aidiary.hatenablog.com/entry/20120701/1341126474">SPTKの使い方 (1) インストール・波形描画・音声再生 | 人工知能に関する断創録</a></li>
<li>SPTKとは: <a href="[http://sp-tk.sourceforge.net/]">Speech Signal Processing Toolkit (SPTK)</a></li>
</ul>


<h1>SPTK with waf</h1>

<p><a href="https://github.com/r9y9/SPTK">SPTK with waf</a>は、SPTKをwafでビルド管理できるようにしたものです。</p>

<ul>
<li>SPTKを共有ライブラリとしてインストールできます。</li>
<li>C、C++の好きな方でコンパイルできます。</li>
<li>wafが使えます（速い、出力がキレイ）</li>
<li>自分のC、C++コードからSPTKのメソッドを呼べます。</li>
<li>コマンドラインツールはインストールされません。</li>
</ul>


<p>コマンドラインツールを使いたい人は、元のconfigure scriptを使えば十分です。</p>

<h1>環境</h1>

<ul>
<li>Unix系</li>
</ul>


<p>Ubuntu 12.04 LTS 64 bitとMac OS X 10.9では確認済み</p>

<h1>SPTKのインストール</h1>

<p>リポジトリをクローンしたあと、</p>

<h2>Build</h2>

<pre><code> ./waf configure &amp;&amp; ./waf
</code></pre>

<h2>Build with clang++</h2>

<pre><code> CXX=clang++ ./waf configure &amp;&amp; ./waf
</code></pre>

<h2>Build with gcc</h2>

<pre><code> git checkout c
 ./waf configure &amp;&amp; ./waf
</code></pre>

<h2>Build with clang</h2>

<pre><code> git checkout c
 CC=clang ./waf configure &amp;&amp; ./waf
</code></pre>

<h2>Install</h2>

<pre><code> sudo ./waf install
</code></pre>

<ul>
<li>Include files: <code>/usr/local/include/SPTK</code></li>
<li>Library: <code>/usr/local/lib/SPTK</code></li>
<li>Pkg-config: <code>/usr/local/lib/pkgconfig</code></li>
</ul>


<p>オリジナルのSPTKとはインストール場所が異なります（オリジナルは、<code>/usr/local/SPTK</code>）</p>

<h1>SPTKを使ってコードを書く</h1>

<p><code>&lt;SPTK/SPTK.h&gt;</code> をインクルードして、好きな関数を呼ぶ</p>

<p>コンパイルは、例えば以下のようにする</p>

<pre><code> g++ test.cpp `pkg-config SPTK --cflags --libs`
</code></pre>

<p>面倒なので、example/ 内のコードを修正して使う（wafを使おう）のがおすすめです。</p>

<br/>


<h1>きっかけ</h1>

<ul>
<li>SPTKはコマンドラインツールだと思ってたけど、どうやらSPTK.hをインクルードすれば一通りのツールを使えるらしい</li>
<li>SPTK.hをインクルードして使う方法のマニュアルが見つからない…</li>
<li>SPTKはC言語で書かれてるし、C++から使うの地味にめんどくさい</li>
</ul>


<h1>C++から簡単に使いたかった</h1>

<ul>
<li>gccやclangだけじゃなくg++やclang++でコンパイルできるようにしよう</li>
<li>自分のコードのビルド管理にはwafを使ってるし、wafで管理できるようにしてしまおう</li>
<li>waf素晴らしいしな （参考: <a href="http://d.hatena.ne.jp/tanakh/20100212">waf チュートリアル | 純粋関数型雑記帳 </a>）</li>
</ul>


<h1>最後に</h1>

<p>SPTKもwafも素晴らしいので積極的に使おう＾＾</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MFCCの計算方法についてメモ]]></title>
    <link href="http://r9y9.github.io/blog/2013/11/24/mfcc-calculation-memo/"/>
    <updated>2013-11-24T22:29:00+09:00</updated>
    <id>http://r9y9.github.io/blog/2013/11/24/mfcc-calculation-memo</id>
    <content type="html"><![CDATA[<h2>MFCC とは</h2>

<p>Mel-Frequency Cepstral Coefficients (MFCCs) のこと。音声認識でよく使われる、音声の特徴表現の代表的なもの。</p>

<h3>算出手順</h3>

<ul>
<li>音声信号を適当な長さのフレームで切り出し</li>
<li>窓がけ</li>
<li>フーリエ変換して対数振幅スペクトルを求める</li>
<li>メルフィルタバンクを掛けて、メル周波数スペクトルを求める</li>
<li>離散コサイン変換により、MFCCを求める</li>
</ul>


<p>以上。SPTKのmfccコマンドのソースもだいたいそうなってた。</p>

<h3>さて</h3>

<h4>ここに音声波形があるじゃろ？？</h4>

<p><img class="center" src="/images/speech-signal.png" title="&ldquo;音声信号を適当な長さのフレームで切り出し&rdquo;" ></p>

<h4>音声波形を窓がけして…</h4>

<p><img class="center" src="/images/windowed-signal.png" title="&ldquo;窓がけ&rdquo;" ></p>

<h4>さらにフーリエ変換して対数取って…</h4>

<p><img class="center" src="/images/log-amplitude.png" title="&ldquo;フーリエ変換して振幅スペクトルを求める&rdquo;" ></p>

<h4>ここでメルフィルタバンクの出番じゃ</h4>

<p><img class="center" src="/images/after-mel-filterbank.png" title="&ldquo;メルフィルタバンクを掛けて、メル周波数スペクトルを求める&rdquo;" ></p>

<h4>最後に離散コサイン変換で完成じゃ</h4>

<p><img class="center" src="/images/MFCC.png" title="&ldquo;離散コサイン変換により、MFCCを求める&rdquo;" ></p>

<h2>まとめ</h2>

<ul>
<li>MFCC求めたかったら、普通はHTKかSPTK使えばいいんじゃないですかね。自分で書くと面倒くさいです</li>
<li>正規化はどうするのがいいのか、まだよくわかってない。単純にDCT（IIを使った）を最後に掛けると、かなり大きい値になって使いにくい。ので、 <a href="http://research.cs.tamu.edu/prism/lectures/sp/l9.pdf">http://research.cs.tamu.edu/prism/lectures/sp/l9.pdf</a> にもあるとおり、mel-filterbankの数（今回の場合は64）で割った。</li>
<li>間違ってるかもしれないけどご愛嬌</li>
</ul>


<h2>参考</h2>

<ul>
<li><a href="http://research.cs.tamu.edu/prism/lectures/sp/l9.pdf">L9: Cepstral analysis [PDF]</a></li>
<li><a href="http://shower.human.waseda.ac.jp/~m-kouki/pukiwiki_public/66.html">メル周波数ケプストラム（MFCC） | Miyazawa’s Pukiwiki 公開版</a></li>
<li><a href="http://aidiary.hatenablog.com/entry/20120225/1330179868">メル周波数ケプストラム係数（MFCC） | 人工知能に関する断創録</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[スペクトログラムとメル周波数スペクトログラムの可視化]]></title>
    <link href="http://r9y9.github.io/blog/2013/11/16/mel-spectrogram/"/>
    <updated>2013-11-16T23:07:00+09:00</updated>
    <id>http://r9y9.github.io/blog/2013/11/16/mel-spectrogram</id>
    <content type="html"><![CDATA[<p>やったので貼っとくだけ</p>

<p><img class="center" src="/images/spectrogram.png" title="&ldquo;よくあるスペクトログラム&rdquo;" ></p>

<p><img class="center" src="/images/mel_spectrogram.png" title="&ldquo;メル周波数に変換したスペクトログラム&rdquo;" ></p>

<p>低周波数の部分は解像度高い、高周波数は粗めというのがメル周波数のような対数周波数の特徴。ただし元々のスペクトルが線形なので、フィルタバンクかけても結果はご覧の通り。</p>

<p>今回は振幅を対数を取って表示した（ちなみに）。上のスペクトログラムは、周波数方向は512次元になっているけど、メル周波数の方は128になっている。直感的には、512次元の線形周波数スペクトルを、人間の聴覚特性に合うようにメル周波数に変換して次元圧縮するイメージ。</p>

<p>解説は、<a href="http://aidiary.hatenablog.com/entry/20120225/1330179868">メル周波数ケプストラム係数（MFCC） | 人工知能に関する断創録</a> を見よう。素晴らしいです</p>

<p>僕はと言えば特に解説する気も起きないので、C++コードでも貼っとこう（※間違ってたので、とりあえず消しました</p>

<h2>まとめ</h2>

<p>メルフィルタバンクかけるクラス作ってたら数時間潰した</p>

<h2>参考</h2>

<ul>
<li><a href="http://aidiary.hatenablog.com/entry/20120225/1330179868">メル周波数ケプストラム係数（MFCC） | 人工知能に関する断創録</a>

<ul>
<li> とても参考にしました。ただ、フィルタバンクかける際に正規化してない？元のスケールを保つために、上のコードでは正規化するようにした(<a href="http://ohm.nuigalway.ie/0809/mbyrne/Images.html#MFCC">ここ</a>の図のようなイメージ）</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
</feed>
